# 100 Days of Python Challenge - Week 7 Summary

## Overview
Week 7 of the 100 Days of Python challenge dives into web technologies, automation, and browser scripting. This week transitions from foundational HTML and CSS to advanced web scraping, browser automation, and interactive web projects, including CSS styling, motivational poster design, data extraction, Spotify playlist automation, price tracking, and intelligent browser bots.

## Projects Completed

### Day 43 - Introduction to CSS
- **Concept**: Cascading Style Sheets (CSS) for styling and formatting web pages, focusing on selectors, properties, and layout fundamentals.
- **Project**: Styled HTML elements with CSS, demonstrating responsive design, color schemes, typography, and box model manipulation.
- **Skills**: CSS syntax and structure, selector specificity, box model, text and font styling, color theory, and basic layout techniques.

### Day 44 - Intermediate CSS - Motivational Poster
- **Concept**: Responsive web design and intermediate CSS techniques, including flexbox, responsive typography, and modern effects.
- **Project**: Motivational poster webpage with flexbox layout, responsive images, Google Fonts, and smooth hover animations.
- **Skills**: Flexbox, CSS transitions, responsive typography with `clamp()`, media queries, custom properties, and professional styling.

### Day 45 - Web Scraping with Beautiful Soup
- **Concept**: Data extraction from websites using Beautiful Soup, HTTP requests, and JSON data handling.
- **Project**: Movie and news scraper extracting and processing data from web pages, outputting structured JSON files.
- **Skills**: Beautiful Soup parsing, CSS selectors, regular expressions, HTTP requests, JSON serialization, and data sorting.

### Day 46 - Create a Spotify Playlist using the Musical Time Machine
- **Concept**: Combining web scraping with API integration and OAuth2 authentication to automate playlist creation.
- **Project**: Scrapes Billboard Hot 100 charts and creates a Spotify playlist with those songs, handling authentication and error recovery.
- **Skills**: Spotify API, OAuth2 flow, local HTTP server, Beautiful Soup scraping, threading, JSON processing, and robust error handling.

### Day 47 - Automated Jiji Price Tracker
- **Concept**: Automated price tracking and email notifications using web scraping and data cleaning.
- **Project**: Scrapes Jiji.co.ke for electric height adjustable desks, sorts by price, and emails the top 5 cheapest deals.
- **Skills**: Beautiful Soup, HTTP headers, regex for price parsing, SMTP email automation, JSON handling, and environment variable management.

### Day 48 - Selenium Webdriver Browser Automation
- **Concept**: Browser automation and dynamic web scraping using Selenium, with parallel processing and game bot logic.
- **Project**: Scrapes Jiji.co.ke for desk listings using Selenium, opens multiple tabs for vendor info, and automates the Cookie Clicker game.
- **Skills**: Selenium Webdriver, JavaScript execution, multi-tab management, event loops, HTML email, and modular code structure.

### Day 49 - Automated Gym Class Booking Bot
- **Concept**: Intelligent browser automation for booking gym classes, handling authentication, and interactive CLI workflows.
- **Project**: Selenium bot that logs in, scrapes class schedules, and books or waitlists classes based on user input.
- **Skills**: Selenium scripting, advanced selectors, retry logic, CLI design, DOM state tracking, and robust error handling.

## Key Learning Outcomes
- **CSS and Responsive Design**: Mastered CSS fundamentals, responsive layouts, and modern web styling techniques.
- **Web Scraping**: Extracted and processed data from static and dynamic web pages using Beautiful Soup and Selenium.
- **API Integration and Automation**: Automated playlist creation and data flows using APIs and OAuth2 authentication.
- **Browser Automation**: Controlled browsers for scraping, data extraction, and interactive automation with Selenium.
- **Email and Notification Systems**: Automated email alerts and reports with HTML formatting and robust error handling.
- **Data Cleaning and Persistence**: Used regex, JSON, and modular code for clean, persistent data storage.
- **Interactive CLI Tools**: Built command-line interfaces for user-driven automation workflows.
- **Security and Environment Management**: Managed credentials and configuration securely with environment variables.

## Progress

**Week 7 Completed**: Days 43-49 completed with 7 projects focused on CSS, web scraping, browser automation, and interactive web tools.